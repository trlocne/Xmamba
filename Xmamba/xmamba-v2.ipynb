{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10071241,"sourceType":"datasetVersion","datasetId":6207571}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":41218.443551,"end_time":"2024-12-03T06:35:58.383837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-02T19:08:59.940286","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup environment","metadata":{"papermill":{"duration":0.008386,"end_time":"2024-12-02T19:09:02.270588","exception":false,"start_time":"2024-12-02T19:09:02.262202","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n\n!python -c \"import matplotlib\" || pip install -q matplotlib\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:18:09.774455Z","iopub.execute_input":"2024-12-03T13:18:09.774850Z","iopub.status.idle":"2024-12-03T13:18:22.026604Z","shell.execute_reply.started":"2024-12-03T13:18:09.774819Z","shell.execute_reply":"2024-12-03T13:18:22.025528Z"},"papermill":{"duration":12.022239,"end_time":"2024-12-02T19:09:14.301496","exception":false,"start_time":"2024-12-02T19:09:02.279257","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mamba_ssm\n!pip install causal_conv1d","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:18:22.028393Z","iopub.execute_input":"2024-12-03T13:18:22.029168Z","iopub.status.idle":"2024-12-03T13:19:10.163134Z","shell.execute_reply.started":"2024-12-03T13:18:22.029126Z","shell.execute_reply":"2024-12-03T13:19:10.162275Z"},"papermill":{"duration":46.67562,"end_time":"2024-12-02T19:10:00.985155","exception":false,"start_time":"2024-12-02T19:09:14.309535","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup imports","metadata":{"papermill":{"duration":0.016117,"end_time":"2024-12-02T19:10:01.019087","exception":false,"start_time":"2024-12-02T19:10:01.002970","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from __future__ import annotations\nimport torch.nn as nn\nimport torch \nfrom functools import partial\nimport glob\nimport json\nimport os\nimport shutil\nimport tempfile\nimport time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nibabel as nib\nimport torch.nn.functional as F \nfrom torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:10.164585Z","iopub.execute_input":"2024-12-03T13:19:10.164955Z","iopub.status.idle":"2024-12-03T13:19:11.909370Z","shell.execute_reply.started":"2024-12-03T13:19:10.164927Z","shell.execute_reply":"2024-12-03T13:19:11.908503Z"},"papermill":{"duration":1.865667,"end_time":"2024-12-02T19:10:02.902074","exception":false,"start_time":"2024-12-02T19:10:01.036407","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mamba_ssm","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:11.911751Z","iopub.execute_input":"2024-12-03T13:19:11.912706Z","iopub.status.idle":"2024-12-03T13:19:13.224862Z","shell.execute_reply.started":"2024-12-03T13:19:11.912663Z","shell.execute_reply":"2024-12-03T13:19:13.223884Z"},"papermill":{"duration":1.068313,"end_time":"2024-12-02T19:10:03.981864","exception":false,"start_time":"2024-12-02T19:10:02.913551","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.networks.blocks.dynunet_block import UnetOutBlock\nfrom monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrUpBlock\nfrom monai.data import DataLoader, decollate_batch, Dataset\nfrom monai.config import print_config\nfrom monai.losses import DiceCELoss, DiceLoss\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric\nfrom monai.transforms import (\n    Activations,\n    AsDiscrete,\n    Compose,\n    LoadImaged,\n    MapTransform,\n    NormalizeIntensityd,\n    Orientationd,\n    RandFlipd,\n    RandScaleIntensityd,\n    RandShiftIntensityd,\n    RandSpatialCropd,\n    Spacingd,\n    EnsureTyped,\n    EnsureChannelFirstd,\n    CropForegroundd,\n    Resized,\n    SpatialPadd,\n    CenterSpatialCropd,\n    RandAffined,\n    RandGaussianNoised,\n    RandAdjustContrastd\n)\n\nfrom monai.utils import set_determinism\n\nprint_config()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:13.226051Z","iopub.execute_input":"2024-12-03T13:19:13.226610Z","iopub.status.idle":"2024-12-03T13:19:50.546949Z","shell.execute_reply.started":"2024-12-03T13:19:13.226569Z","shell.execute_reply":"2024-12-03T13:19:50.546027Z"},"papermill":{"duration":33.098033,"end_time":"2024-12-02T19:10:37.091728","exception":false,"start_time":"2024-12-02T19:10:03.993695","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup data directory","metadata":{"papermill":{"duration":0.012179,"end_time":"2024-12-02T19:10:37.116287","exception":false,"start_time":"2024-12-02T19:10:37.104108","status":"completed"},"tags":[]}},{"cell_type":"code","source":"directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n\nif directory is not None:\n\n    os.makedirs(directory, exist_ok=True)\n\nroot_dir = tempfile.mkdtemp() if directory is None else directory\n\nprint(root_dir)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:50.548198Z","iopub.execute_input":"2024-12-03T13:19:50.549004Z","iopub.status.idle":"2024-12-03T13:19:50.554609Z","shell.execute_reply.started":"2024-12-03T13:19:50.548960Z","shell.execute_reply":"2024-12-03T13:19:50.553753Z"},"papermill":{"duration":0.020589,"end_time":"2024-12-02T19:10:37.149047","exception":false,"start_time":"2024-12-02T19:10:37.128458","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup average meter, fold reader, checkpoint saver","metadata":{"papermill":{"duration":0.014085,"end_time":"2024-12-02T19:10:37.176388","exception":false,"start_time":"2024-12-02T19:10:37.162303","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = np.where(self.count > 0, self.sum / self.count, self.sum)\n\n\ndef datafold_read(datalist, basedir, fold=0, key=\"training\"):\n    with open(datalist) as f:\n        json_data = json.load(f)\n\n    json_data = json_data[key]\n\n    for d in json_data:\n        for k in d:\n            if isinstance(d[k], list):\n                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n            elif isinstance(d[k], str):\n                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n\n    tr = []\n    val = []\n    for d in json_data:\n        if \"fold\" in d and d[\"fold\"] == fold:\n            val.append(d)\n        else:\n            tr.append(d)\n\n    return tr, val","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:50.555536Z","iopub.execute_input":"2024-12-03T13:19:50.555860Z","iopub.status.idle":"2024-12-03T13:19:50.571630Z","shell.execute_reply.started":"2024-12-03T13:19:50.555824Z","shell.execute_reply":"2024-12-03T13:19:50.570803Z"},"papermill":{"duration":0.025611,"end_time":"2024-12-02T19:10:37.215748","exception":false,"start_time":"2024-12-02T19:10:37.190137","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup dataloader","metadata":{"papermill":{"duration":0.012933,"end_time":"2024-12-02T19:10:37.242702","exception":false,"start_time":"2024-12-02T19:10:37.229769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n    \"\"\"\n    Convert labels to multi channels based on brats classes:\n    label 1 is NETC\n    label 2 is SNFH\n    label 3 is ET\n    label 4 is RC\n    The possible classes are TC (Tumor core), WT (Whole tumor)\n    and ET (Enhancing tumor).\n\n    \"\"\"\n    def __call__(self, data):\n        d = dict(data)\n        for key in self.keys:\n            result = []\n            result.append(torch.logical_or(d[key] == 1, d[key] == 3))\n            result.append(torch.logical_or(torch.logical_or(d[key] == 1, d[key] == 3), d[key] == 2))\n            result.append(d[key] == 3)\n            result.append(d[key] == 4)\n            d[key] = torch.stack(result, axis=0).float()\n        return d","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:50.572749Z","iopub.execute_input":"2024-12-03T13:19:50.573492Z","iopub.status.idle":"2024-12-03T13:19:50.588823Z","shell.execute_reply.started":"2024-12-03T13:19:50.573453Z","shell.execute_reply":"2024-12-03T13:19:50.587982Z"},"papermill":{"duration":0.022163,"end_time":"2024-12-02T19:10:37.278247","exception":false,"start_time":"2024-12-02T19:10:37.256084","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_loader():\n    training = {\"training\": []}\n    items = sorted(glob.glob('/kaggle/input/BraTS2024_small_dataset/*')) \n    fold = -1; \n    for i in range(len(items)):   \n        if fold > 3:\n            fold = -1            \n        fold = fold + 1\n        if i >= 150:   \n            break   \n        values = sorted(glob.glob(f\"{items[i]}/*\"))      \n        training[\"training\"].extend([{\"fold\": fold,\"image\": values[1:], \"label\": values[0]}])         \n    with open('training_data.json', 'w') as file:      \n        json.dump(training, file)\n    train_files, validation_files = datafold_read(datalist=\"/kaggle/working/training_data.json\", basedir='', fold=1)\n    \n    # Training Transform\n    train_transform = Compose(\n        [\n            LoadImaged(keys=[\"image\", \"label\"]),\n            EnsureChannelFirstd(keys=\"image\"),\n            EnsureTyped(keys=[\"image\", \"label\"]),\n            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n            Spacingd(\n                keys=[\"image\", \"label\"],\n                pixdim=(1.0, 1.0, 1.0),\n                mode=(\"bilinear\", \"nearest\"),\n            ),\n            Resized(keys=[\"image\", \"label\"], spatial_size=[128, 128 , 128]),\n            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n        ]\n    )\n\n    # Validation Transform\n    val_transform = Compose(\n        [\n            LoadImaged(keys=[\"image\", \"label\"]),\n            EnsureChannelFirstd(keys=\"image\"),\n            EnsureTyped(keys=[\"image\", \"label\"]),\n            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n            Spacingd(\n                keys=[\"image\", \"label\"],\n                pixdim=(1.0, 1.0, 1.0),\n                mode=(\"bilinear\", \"nearest\"),\n            ),\n            Resized(keys=[\"image\", \"label\"], spatial_size=[128, 128 , 128]),\n            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n        ]\n    )\n\n\n\n    train_ds = Dataset(data=train_files, transform=train_transform)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=1,\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True,\n    )\n    val_ds = Dataset(data=validation_files, transform=val_transform)\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=1,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True,\n    )\n\n\n\n    return train_loader, val_loader, train_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:50.590053Z","iopub.execute_input":"2024-12-03T13:19:50.590364Z","iopub.status.idle":"2024-12-03T13:19:50.603984Z","shell.execute_reply.started":"2024-12-03T13:19:50.590330Z","shell.execute_reply":"2024-12-03T13:19:50.603186Z"},"papermill":{"duration":0.026603,"end_time":"2024-12-02T19:10:37.318211","exception":false,"start_time":"2024-12-02T19:10:37.291608","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Set dataset root directory and hyper-parameters","metadata":{"papermill":{"duration":0.012366,"end_time":"2024-12-02T19:10:37.343006","exception":false,"start_time":"2024-12-02T19:10:37.330640","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_loader, val_loader, train_ds, val_ds= get_loader()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:50.607385Z","iopub.execute_input":"2024-12-03T13:19:50.607651Z","iopub.status.idle":"2024-12-03T13:19:51.185313Z","shell.execute_reply.started":"2024-12-03T13:19:50.607627Z","shell.execute_reply":"2024-12-03T13:19:51.184555Z"},"papermill":{"duration":0.886488,"end_time":"2024-12-02T19:10:38.241626","exception":false,"start_time":"2024-12-02T19:10:37.355138","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check data shape and visualize","metadata":{"papermill":{"duration":0.014296,"end_time":"2024-12-02T19:10:38.270661","exception":false,"start_time":"2024-12-02T19:10:38.256365","status":"completed"},"tags":[]}},{"cell_type":"code","source":"img_add = os.path.join(\"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-t1c.nii\")\n\nlabel_add = os.path.join(\"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-seg.nii\")\n\nimg = nib.load(img_add).get_fdata()\n\nlabel = nib.load(label_add).get_fdata()\n\nprint(f\"image shape: {img.shape}, label shape: {label.shape}\")\n\nplt.figure(\"image\", (18, 6))\n\nplt.subplot(1, 2, 1)\n\nplt.title(\"image\")\n\nplt.imshow(img[:, :, 135], cmap=\"gray\")\n\nplt.subplot(1, 2, 2)\n\nplt.title(\"label\")\n\nplt.imshow(label[:, :, 135])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:51.186220Z","iopub.execute_input":"2024-12-03T13:19:51.186473Z","iopub.status.idle":"2024-12-03T13:19:51.807559Z","shell.execute_reply.started":"2024-12-03T13:19:51.186448Z","shell.execute_reply":"2024-12-03T13:19:51.806751Z"},"papermill":{"duration":0.68182,"end_time":"2024-12-02T19:10:38.966801","exception":false,"start_time":"2024-12-02T19:10:38.284981","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create SegMamba model\n  ","metadata":{"papermill":{"duration":0.013919,"end_time":"2024-12-02T19:10:38.994437","exception":false,"start_time":"2024-12-02T19:10:38.980518","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from torch.cuda.amp import custom_bwd, custom_fwd\nimport causal_conv1d_cuda\nimport selective_scan_cuda\nclass MambaInnerFnNoOutProj(torch.autograd.Function):\n    @staticmethod\n    @custom_fwd\n    def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n                A, B=None, C=None, D=None, delta_bias=None, B_proj_bias=None,\n                C_proj_bias=None, delta_softplus=True, checkpoint_lvl=1):\n        \"\"\"\n             xz: (batch, dim, seqlen)\n        \"\"\"\n        assert checkpoint_lvl in [0, 1]\n        L = xz.shape[-1]\n        delta_rank = delta_proj_weight.shape[1]\n        d_state = A.shape[-1] * (1 if not A.is_complex() else 2)\n        if torch.is_autocast_enabled():\n            x_proj_weight = x_proj_weight.to(dtype=torch.get_autocast_gpu_dtype())\n            delta_proj_weight = delta_proj_weight.to(dtype=torch.get_autocast_gpu_dtype())\n        if xz.stride(-1) != 1:\n            xz = xz.contiguous()\n        conv1d_weight = rearrange(conv1d_weight, \"d 1 w -> d w\")\n        x, z = xz.chunk(2, dim=1)\n        conv1d_bias = conv1d_bias.contiguous() if conv1d_bias is not None else None\n        conv1d_out = causal_conv1d_cuda.causal_conv1d_fwd(\n            x, conv1d_weight, conv1d_bias, None, None, None, True\n        )\n        # We're being very careful here about the layout, to avoid extra transposes.\n        # We want delta to have d as the slowest moving dimension\n        # and L as the fastest moving dimension, since those are what the ssm_scan kernel expects.\n        x_dbl = F.linear(rearrange(conv1d_out, 'b d l -> (b l) d'), x_proj_weight)  # (bl d)\n        delta = rearrange(delta_proj_weight @ x_dbl[:, :delta_rank].t(), \"d (b l) -> b d l\", l = L)\n        ctx.is_variable_B = B is None\n        ctx.is_variable_C = C is None\n        ctx.B_proj_bias_is_None = B_proj_bias is None\n        ctx.C_proj_bias_is_None = C_proj_bias is None\n        if B is None:  # variable B\n            B = x_dbl[:, delta_rank:delta_rank + d_state]  # (bl dstate)\n            if B_proj_bias is not None:\n                B = B + B_proj_bias.to(dtype=B.dtype)\n            if not A.is_complex():\n                # B = rearrange(B, \"(b l) dstate -> b dstate l\", l=L).contiguous()\n                B = rearrange(B, \"(b l) dstate -> b 1 dstate l\", l=L).contiguous()\n            else:\n                B = rearrange(B, \"(b l) (dstate two) -> b 1 dstate (l two)\", l=L, two=2).contiguous()\n        else:\n            if B.stride(-1) != 1:\n                B = B.contiguous()\n        if C is None:  # variable C\n            C = x_dbl[:, -d_state:]  # (bl dstate)\n            if C_proj_bias is not None:\n                C = C + C_proj_bias.to(dtype=C.dtype)\n            if not A.is_complex():\n                # C = rearrange(C, \"(b l) dstate -> b dstate l\", l=L).contiguous()\n                C = rearrange(C, \"(b l) dstate -> b 1 dstate l\", l=L).contiguous()\n            else:\n                C = rearrange(C, \"(b l) (dstate two) -> b 1 dstate (l two)\", l=L, two=2).contiguous()\n        else:\n            if C.stride(-1) != 1:\n                C = C.contiguous()\n        if D is not None:\n            D = D.contiguous()\n        out, scan_intermediates, out_z = selective_scan_cuda.fwd(\n            conv1d_out, delta, A, B, C, D, z, delta_bias, delta_softplus\n        )\n        ctx.delta_softplus = delta_softplus\n        ctx.checkpoint_lvl = checkpoint_lvl\n        if checkpoint_lvl >= 1:  # Will recompute conv1d_out and delta in the backward pass\n            conv1d_out, delta = None, None\n        ctx.save_for_backward(xz, conv1d_weight, conv1d_bias, x_dbl, x_proj_weight,\n                              delta_proj_weight, conv1d_out, delta,\n                              A, B, C, D, delta_bias, scan_intermediates, out)\n        # return rearrange(out_z, \"b d l -> b l d\")\n        return out_z\n\n    @staticmethod\n    @custom_bwd\n    def backward(ctx, dout):\n        # dout: (batch, seqlen, dim)\n        (xz, conv1d_weight, conv1d_bias, x_dbl, x_proj_weight, delta_proj_weight, \n         conv1d_out, delta, A, B, C, D, delta_bias, scan_intermediates, out) = ctx.saved_tensors\n        L = xz.shape[-1]\n        delta_rank = delta_proj_weight.shape[1]\n        d_state = A.shape[-1] * (1 if not A.is_complex() else 2)\n        x, z = xz.chunk(2, dim=1)\n        if dout.stride(-1) != 1:\n            dout = dout.contiguous()\n        if ctx.checkpoint_lvl == 1:\n            conv1d_out = causal_conv1d_cuda.causal_conv1d_fwd(\n                x, conv1d_weight, conv1d_bias, None, None, None, True\n            )\n            delta = rearrange(delta_proj_weight @ x_dbl[:, :delta_rank].t(),\n                              \"d (b l) -> b d l\", l = L)\n        # The kernel supports passing in a pre-allocated dz (e.g., in case we want to fuse the\n        # backward of selective_scan_cuda with the backward of chunk).\n        dxz = torch.empty_like(xz)  # (batch, dim, seqlen)\n        dx, dz = dxz.chunk(2, dim=1)\n        # dout_y = rearrange(dout, \"b l d -> b d l\") # because no arrange at end of forward, so dout shape is b d l\n        dconv1d_out, ddelta, dA, dB, dC, dD, ddelta_bias, dz, out_z = selective_scan_cuda.bwd(\n            conv1d_out, delta, A, B, C, D, z, delta_bias, dout, scan_intermediates, out, dz,\n            ctx.delta_softplus,\n            True  # option to recompute out_z\n        )\n        dD = dD if D is not None else None\n        dx_dbl = torch.empty_like(x_dbl)\n        dB_proj_bias = None\n        if ctx.is_variable_B:\n            if not A.is_complex():\n                dB = rearrange(dB, \"b 1 dstate l -> (b l) dstate\").contiguous()\n            else:\n                dB = rearrange(dB, \"b 1 dstate (l two) -> (b l) (dstate two)\", two=2).contiguous()\n            dB_proj_bias = dB.sum(0) if not ctx.B_proj_bias_is_None else None\n            dx_dbl[:, delta_rank:delta_rank + d_state] = dB  # (bl d)\n            dB = None\n        dC_proj_bias = None\n        if ctx.is_variable_C:\n            if not A.is_complex():\n                dC = rearrange(dC, \"b 1 dstate l -> (b l) dstate\").contiguous()\n            else:\n                dC = rearrange(dC, \"b 1 dstate (l two) -> (b l) (dstate two)\", two=2).contiguous()\n            dC_proj_bias = dC.sum(0) if not ctx.C_proj_bias_is_None else None\n            dx_dbl[:, -d_state:] = dC  # (bl d)\n            dC = None\n        ddelta = rearrange(ddelta, \"b d l -> d (b l)\")\n        ddelta_proj_weight = torch.einsum(\"dB,Br->dr\", ddelta, x_dbl[:, :delta_rank])\n        dx_dbl[:, :delta_rank] = torch.einsum(\"dB,dr->Br\", ddelta, delta_proj_weight)\n        dconv1d_out = rearrange(dconv1d_out, \"b d l -> d (b l)\")\n        dx_proj_weight = torch.einsum(\"Br,Bd->rd\", dx_dbl, rearrange(conv1d_out, \"b d l -> (b l) d\"))\n        dconv1d_out = torch.addmm(dconv1d_out, x_proj_weight.t(), dx_dbl.t(), out=dconv1d_out)\n        dconv1d_out = rearrange(dconv1d_out, \"d (b l) -> b d l\", b=x.shape[0], l=x.shape[-1])\n        # The kernel supports passing in a pre-allocated dx (e.g., in case we want to fuse the\n        # backward of conv1d with the backward of chunk).\n        dx, dconv1d_weight, dconv1d_bias, *_ = causal_conv1d_cuda.causal_conv1d_bwd(\n            x, conv1d_weight, conv1d_bias, dconv1d_out, None, None, None, dx, False, True\n        )\n        dconv1d_bias = dconv1d_bias if conv1d_bias is not None else None\n        dconv1d_weight = rearrange(dconv1d_weight, \"d w -> d 1 w\")\n        return (dxz, dconv1d_weight, dconv1d_bias, dx_proj_weight, ddelta_proj_weight,\n                dA, dB, dC, dD,\n                ddelta_bias if delta_bias is not None else None,\n                dB_proj_bias, dC_proj_bias, None)\n\ndef mamba_inner_fn_no_out_proj(\n    xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n    A, B=None, C=None, D=None, delta_bias=None, B_proj_bias=None,\n    C_proj_bias=None, delta_softplus=True\n):\n    return MambaInnerFnNoOutProj.apply(xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n                              A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:51.808956Z","iopub.execute_input":"2024-12-03T13:19:51.809319Z","iopub.status.idle":"2024-12-03T13:19:51.832567Z","shell.execute_reply.started":"2024-12-03T13:19:51.809269Z","shell.execute_reply":"2024-12-03T13:19:51.831672Z"},"papermill":{"duration":0.038729,"end_time":"2024-12-02T19:10:39.047123","exception":false,"start_time":"2024-12-02T19:10:39.008394","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copyright (c) 2023, Tri Dao, Albert Gu.\n\nimport math\nfrom typing import Optional\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\n\nfrom einops import rearrange, repeat\n\ntry:\n    import causal_conv1d_fn, causal_conv1d_update\nexcept ImportError:\n    causal_conv1d_fn, causal_conv1d_update = None, None\n\ntry:\n    from mamba_ssm.ops.triton.selective_state_update import selective_state_update\nexcept ImportError:\n    selective_state_update = None\n\ntry:\n    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\nexcept ImportError:\n    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n\nclass XMamba(nn.Module):\n    def __init__(\n        self,\n        d_model,\n        d_state=16,\n        d_conv=4,\n        expand=2,\n        dt_rank=\"auto\",\n        dt_min=0.001,\n        dt_max=0.1,\n        dt_init=\"random\",\n        dt_scale=1.0,\n        dt_init_floor=1e-4,\n        conv_bias=True,\n        bias=False,\n        use_fast_path=True,  # Fused kernel options\n        layer_idx=None,\n        device=None,\n        dtype=None,\n        nslices=5\n    ):\n        self.factory_kwargs = {\"device\": device, \"dtype\": dtype}\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = int(self.expand * self.d_model)\n        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == \"auto\" else dt_rank\n        self.use_fast_path = use_fast_path\n        self.layer_idx = layer_idx\n        self.nslices = nslices\n        self.silu = nn.SiLU()\n\n        self.in_proj = nn.Linear(self.d_model, self.d_inner * 2, bias=bias, **self.factory_kwargs)\n\n        self.activation = \"silu\"\n        self.act = nn.SiLU()\n\n        # S4D real initialization\n        A = repeat(\n            torch.arange(1, self.d_state + 1, dtype=torch.float32, device=device),\n            \"n -> d n\",\n            d=self.d_inner,\n        ).contiguous()\n        A_log = torch.log(A)  # Keep A_log in fp32\n        self.A_log = nn.Parameter(A_log)\n        self.A_log._no_weight_decay = True\n\n        self.conv1d = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            bias=conv_bias,\n            kernel_size=d_conv,\n            groups=self.d_inner,\n            padding=d_conv - 1,\n            **self.factory_kwargs,\n        )\n\n        self.x_proj = nn.Linear(\n            self.d_inner, self.dt_rank + self.d_state * 2, bias=False, **self.factory_kwargs\n        )\n        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True, **self.factory_kwargs)\n\n        # D \"skip\" parameter\n        self.D = nn.Parameter(torch.ones(self.d_inner, device=device))  # Keep in fp32\\\n        self.D._no_weight_decay = True\n\n        # bidirection\n        A_b = repeat(\n            torch.arange(1, self.d_state + 1, dtype=torch.float32, device=device),\n            \"n -> d n\",\n            d=self.d_inner,\n        ).contiguous()\n        A_b_log = torch.log(A_b)  # Keep A_b_log in fp32\n        self.A_b_log = nn.Parameter(A_b_log)\n        self.A_b_log._no_weight_decay = True \n\n        self.conv1d_b = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            bias=conv_bias,\n            kernel_size=d_conv,\n            groups=self.d_inner,\n            padding=d_conv - 1,\n            **self.factory_kwargs,\n        )\n        # trlocthem \n        self.softplus = nn.Softplus()\n        # trlocthem\n        self.x_proj_b = nn.Linear(\n            self.d_inner, self.dt_rank + self.d_state * 2, bias=False, **self.factory_kwargs\n        )\n        self.dt_proj_b = nn.Linear(self.dt_rank, self.d_inner, bias=True, **self.factory_kwargs)\n\n        self.D_b = nn.Parameter(torch.ones(self.d_inner, device=device))  # Keep in fp32\n        self.D_b._no_weight_decay = True\n\n        # spatial\n        A_s = repeat(\n            torch.arange(1, self.d_state + 1, dtype=torch.float32, device=device),\n            \"n -> d n\",\n            d=self.d_inner,\n        ).contiguous()\n        A_s_log = torch.log(A_s)  # Keep A_b_log in fp32\n        self.A_s_log = nn.Parameter(A_s_log)\n        self.A_s_log._no_weight_decay = True \n\n        self.conv1d_s = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            bias=conv_bias,\n            kernel_size=d_conv,\n            groups=self.d_inner,\n            padding=d_conv - 1,\n            **self.factory_kwargs,\n        )\n\n        self.x_proj_s = nn.Linear(\n            self.d_inner, self.dt_rank + self.d_state * 2, bias=False, **self.factory_kwargs\n        )\n        self.dt_proj_s = nn.Linear(self.dt_rank, self.d_inner, bias=True, **self.factory_kwargs)\n\n        self.D_s = nn.Parameter(torch.ones(self.d_inner, device=device))  # Keep in fp32\n        self.D_s._no_weight_decay = True\n\n        self.device = device\n\n        # Initialize special dt projection to preserve variance at initialization\n        dt_init_std = self.dt_rank**-0.5 * dt_scale\n        if dt_init == \"constant\":\n            nn.init.constant_(self.dt_proj.weight, dt_init_std)\n        elif dt_init == \"random\":\n            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)\n        else:\n            raise NotImplementedError\n\n        # Initialize dt bias so that F.softplus(dt_bias) is between dt_min and dt_max\n        dt = torch.exp(\n            torch.rand(self.d_inner, **self.factory_kwargs) * (math.log(dt_max) - math.log(dt_min))\n            + math.log(dt_min)\n        ).clamp(min=dt_init_floor)\n\n        inv_dt = dt + torch.log(-torch.expm1(-dt))\n        with torch.no_grad():\n            self.dt_proj.bias.copy_(inv_dt)\n        # Our initialization would set all Linear.bias to zero, need to mark this one as _no_reinit\n        self.dt_proj.bias._no_reinit = True\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=bias, **self.factory_kwargs)\n        self.tanh = nn.Tanh()\n\n    def WMF(self, *o):\n        k_weights = nn.Parameter(torch.tensor([1/3, 1/3, 1/3]), requires_grad=True)\n        k_weights = torch.softmax(k_weights, dim=0)\n\n        assert len(o) == len(k_weights), \"The number of outputs and weights must match.\"\n\n        O = sum(w * out for w, out in zip(k_weights, o))\n        sp = nn.Softplus()\n        return sp(O)\n\n    #trlocthem\n    def process_direction(\n            self,\n            x: Tensor,\n            conv1d: nn.Conv1d,\n            conv1d_weight, \n            conv1d_bias, \n            x_proj_weight, \n            delta_proj_weight,\n            A, B=None, C=None, D=None, \n            delta_bias=None, \n            B_proj_bias=None,\n            C_proj_bias=None, \n            delta_softplus=True\n    ):\n        x = conv1d(x)\n        x = F.relu(x)\n        x = mamba_inner_fn_no_out_proj(x, conv1d_weight.to(dtype=x.dtype), conv1d_bias.to(dtype=x.dtype), x_proj_weight.to(dtype=x.dtype), delta_proj_weight.to(dtype=x.dtype), A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus)\n        return x\n    #trlocthem\n\n    def gaussian_decay_mask(self , sequence):\n        length = sequence.shape[1]\n        # Automatically determine center and last index\n        center_index = (length + 1) // 2\n\n        ref_index = center_index\n        ref_vector = sequence[:, center_index, :]\n\n        # Index-based Gaussian mask\n        indices = torch.arange(length, dtype=torch.float32, device=sequence.device)\n        sigma1 = torch.abs(indices - ref_index).mean()  # Sigma calculation\n        weights1 = torch.exp(-0.5 * ((indices - ref_index) ** 2) / (sigma1 ** 2))\n        weights1 /= weights1.sum()\n        weights1 = weights1.repeat(sequence.size(0), 1)  # Repeat weights for batch dimension\n\n        # Vector-based Gaussian mask\n        distances = torch.norm(sequence - ref_vector.unsqueeze(1), dim=2)\n        sigma2 = distances.mean(dim=1, keepdim=True)\n        weights2 = torch.exp(-0.5 * (distances / sigma2) ** 2)\n        weights2 = weights2 / weights2.sum(dim=1, keepdim=True)\n\n        combined_weights = weights1  * weights2\n        combined_weights = combined_weights / combined_weights.sum(dim=1, keepdim=True)\n        s_hat_f = sequence * combined_weights.unsqueeze(2)\n        return s_hat_f\n        \n    def forward(self, hidden_states, inference_params=None):\n        \"\"\"\n        hidden_states: (B, L, D)\n        Returns: same shape as hidden_states\n        \"\"\"\n        batch, seqlen, dim = hidden_states.shape\n\n        self.forward_conv1d = nn.Conv1d(\n            in_channels=dim*4, out_channels=dim*4, kernel_size=1, **self.factory_kwargs\n        ).cuda(device=self.device)\n        self.backward_conv1d = nn.Conv1d(\n            in_channels=dim*4, out_channels=dim*4, kernel_size=1, **self.factory_kwargs\n        ).cuda(device=self.device)\n        conv_state, ssm_state = None, None\n        if inference_params is not None:\n            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)\n            if inference_params.seqlen_offset > 0:\n                # The states are updated inplace\n                out, _, _ = self.step(hidden_states, conv_state, ssm_state)\n                return out\n\n        # We do matmul and transpose BLH -> HBL at the same time\n        xz = rearrange(\n            self.in_proj.weight @ rearrange(hidden_states, \"b l d -> d (b l)\"),\n            \"d (b l) -> b d l\",\n            l=seqlen,\n        )\n\n        \n        if self.in_proj.bias is not None:\n            xz = xz + rearrange(self.in_proj.bias.to(dtype=xz.dtype), \"d -> d 1\")\n        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)\n        # In the backward pass we write dx and dz next to each other to avoid torch.cat\n        self.center = (seqlen + 1) // 2\n        proj1 = nn.Linear(dim, dim, **self.factory_kwargs).cuda(device=device)\n        proj2 = nn.Linear(dim*2, dim*2, **self.factory_kwargs).cuda(device=device)\n        self.norm = nn.LayerNorm(dim*2).cuda(device=self.device)\n        # self.norm.weight = self.norm.weight.to(self.device)\n        # self.norm.bias = self.norm.bias.to(self.device)\n        self.adapool = nn.AdaptiveAvgPool1d(2*dim)\n        if self.use_fast_path and inference_params is None:  # Doesn't support outputting the states\n                self.norm = self.norm.to(self.device)\n                skip = xz\n                out_f = self.process_direction(\n                    xz[:, :, : self.center],\n                    self.forward_conv1d,\n                    self.conv1d.weight,\n                    self.conv1d.bias,\n                    self.x_proj.weight,\n                    self.dt_proj.weight,\n                    A,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D.float(),\n                    self.dt_proj.bias.float(),\n                    None, # B_proj_bias\n                    None, # C_proj_bias\n                    True, # delta_softplus\n                ) # (B, D, S)\n                out_bw = self.process_direction(\n                    xz[:, :, self.center :].flip([-1]),\n                    self.backward_conv1d,\n                    self.conv1d.weight,\n                    self.conv1d.bias,\n                    self.x_proj.weight,\n                    self.dt_proj.weight,\n                    A,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D.float(),\n                    self.dt_proj.bias.float(),\n                    None,\n                    None,\n                    True,\n                ) # (B, D, S)\n                out_f = rearrange(out_f, 'b d n -> b n d')\n                out_f = self.gaussian_decay_mask(out_f)\n                out_f = self.silu(out_f)\n            \n                out_bw = rearrange(out_bw, 'b d n -> b n d')\n                out_bw = self.gaussian_decay_mask(out_bw)\n                out_bw = self.silu(out_bw)\n\n                \n                out = torch.cat([out_f, out_bw.flip([-1])], dim=-2)\n                out = proj2(out)\n                out = rearrange(out, 'b n d -> b d n')\n                skip = self.adapool(rearrange(skip, 'b n d -> b d n'))\n                skip = rearrange(skip, 'b d n -> b n d')\n                out = out + skip\n                out = out.permute(0, 2, 1)\n                out = self.norm(out)\n                out = out.permute(0, 2, 1)\n                out = self.tanh(out)\n\n                A_b = -torch.exp(self.A_b_log.float())\n                skip1 = xz.flip([-1])\n                out_bf = self.process_direction(\n                    skip1[:, :, : self.center],\n                    self.forward_conv1d,\n                    self.conv1d_b.weight,\n                    self.conv1d_b.bias,\n                    self.x_proj_b.weight,\n                    self.dt_proj_b.weight,\n                    A_b,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D_b.float(),\n                    self.dt_proj_b.bias.float(),\n                    None,\n                    None,\n                    True,\n                )\n\n                out_bbw = self.process_direction(\n                    skip1[:, :, self.center :].flip([-1]),\n                    self.backward_conv1d,\n                    self.conv1d_b.weight,\n                    self.conv1d_b.bias,\n                    self.x_proj_b.weight,\n                    self.dt_proj_b.weight,\n                    A_b,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D_b.float(),\n                    self.dt_proj_b.bias.float(),\n                    None,\n                    None,\n                    True,\n                ) \n                # (B, D, S)\n                out_bf = rearrange(out_bf, 'b d n -> b n d')\n                out_bf = self.gaussian_decay_mask(out_bf)\n                out_bf = self.silu(out_bf)\n\n                out_bbw = rearrange(out_bbw, 'b d n -> b n d')\n                out_bbw = self.gaussian_decay_mask(out_bbw)\n                out_bbw = self.silu(out_bbw)\n\n                out_b = torch.cat([out_bf, out_bbw.flip([-1])], dim=-2)\n                out_b = proj2(out_b)\n                out_b = rearrange(out_b, 'b n d -> b d n')\n                skip1 = self.adapool(rearrange(skip1, 'b n d -> b d n'))\n                skip1 = rearrange(skip1, 'b d n -> b n d')\n                out_b = out_b + skip1\n                out_b = out_b.permute(0, 2, 1)\n                out_b = self.norm(out_b)\n                out_b = out_b.permute(0, 2, 1)\n                out_b = self.tanh(out_b)\n\n                A_s = -torch.exp(self.A_s_log.float())\n                xz_s = xz.chunk(self.nslices, dim=-1)\n                xz_s = torch.stack(xz_s,dim=-1)\n                xz_s = xz_s.flatten(-2)\n                skip2 = xz_s\n                # self.adapool = nn.AdaptiveAvgPool1d(skip2.shape[2])\n                out_sf = self.process_direction(\n                    skip2[:, :, : self.center],\n                    self.forward_conv1d,\n                    self.conv1d_s.weight,\n                    self.conv1d_s.bias,\n                    self.x_proj_s.weight,\n                    self.dt_proj_s.weight,\n                    A_s,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D_s.float(),\n                    self.dt_proj_s.bias.float(),\n                    None,\n                    None,\n                    True,\n                )\n                \n                out_sbw = self.process_direction(\n                    skip2[:, :, self.center :].flip([-1]),\n                    self.backward_conv1d,\n                    self.conv1d_s.weight,\n                    self.conv1d_s.bias,\n                    self.x_proj_s.weight,\n                    self.dt_proj_s.weight,\n                    A_s,\n                    None,  # input-dependent B\n                    None,  # input-dependent C\n                    self.D_s.float(),\n                    self.dt_proj_s.bias.float(),\n                    None,\n                    None,\n                    True,\n                ) # (B, D, S)\n\n                out_sf = out_sf.reshape(batch,self.d_inner, -1)\n                out_sf = rearrange(out_sf, 'b d n -> b n d')\n                out_sf = self.gaussian_decay_mask(out_sf)\n                out_sf = self.silu(out_sf)\n\n                out_sbw = out_sbw.reshape(batch,self.d_inner, -1)\n                out_sbw = rearrange(out_sbw, 'b d n -> b n d')\n                out_sbw = self.gaussian_decay_mask(out_sbw)\n                out_sbw = self.silu(out_sbw)\n\n                out_s = torch.cat([out_sf, out_sbw.flip([-1])], dim=-2)\n                out_s = proj2(out_s)\n                out_s = rearrange(out_s, 'b n d -> b d n')\n                skip2 = self.adapool(rearrange(skip2, 'b n d -> b d n'))\n                skip2 = rearrange(skip2, 'b d n -> b n d')\n                out_s = out_s + skip2\n                out_s = out_s.permute(0, 2, 1)\n                out_s = self.norm(out_s)\n                out_s = out_s.permute(0, 2, 1)\n                out_s = self.tanh(out_s)\n                \n                out_s = out_s.reshape(batch,self.d_inner,seqlen//self.nslices,self.nslices).permute(0,1,3,2).flatten(-2)\n\n                out = self.WMF(out, out_b.flip([-1]), out_s) \n                out = rearrange(out, \"b d l -> b l d\")  # Rearrange the tensor as needed\n                out = F.linear(out, self.out_proj.weight, self.out_proj.bias)\n            \n        return out\n    \n    \n\n    def step(self, hidden_states, conv_state, ssm_state):\n        dtype = hidden_states.dtype\n        assert hidden_states.shape[1] == 1, \"Only support decoding with 1 token at a time for now\"\n        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)\n        x, z = xz.chunk(2, dim=-1)  # (B D)\n\n        # Conv step\n        if causal_conv1d_update is None:\n            conv_state.copy_(torch.roll(conv_state, shifts=-1, dims=-1))  # Update state (B D W)\n            conv_state[:, :, -1] = x\n            x = torch.sum(conv_state * rearrange(self.conv1d.weight, \"d 1 w -> d w\"), dim=-1)  # (B D)\n            if self.conv1d.bias is not None:\n                x = x + self.conv1d.bias\n            x = self.act(x).to(dtype=dtype)\n        else:\n            x = causal_conv1d_update(\n                x,\n                conv_state,\n                rearrange(self.conv1d.weight, \"d 1 w -> d w\"),\n                self.conv1d.bias,\n                self.activation,\n            )\n\n        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)\n        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)\n        # Don't add dt_bias here\n        dt = F.linear(dt, self.dt_proj.weight)  # (B d_inner)\n        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)\n\n        # SSM step\n        if selective_state_update is None:\n            # Discretize A and B\n            dt = F.softplus(dt + self.dt_proj.bias.to(dtype=dt.dtype))\n            dA = torch.exp(torch.einsum(\"bd,dn->bdn\", dt, A))\n            dB = torch.einsum(\"bd,bn->bdn\", dt, B)\n            ssm_state.copy_(ssm_state * dA + rearrange(x, \"b d -> b d 1\") * dB)\n            y = torch.einsum(\"bdn,bn->bd\", ssm_state.to(dtype), C)\n            y = y + self.D.to(dtype) * x\n            y = y * self.act(z)  # (B D)\n        else:\n            y = selective_state_update(\n                ssm_state, x, dt, A, B, C, self.D, z=z, dt_bias=self.dt_proj.bias, dt_softplus=True\n            )\n\n        out = self.out_proj(y)\n        return out.unsqueeze(1), conv_state, ssm_state\n\n    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n        device = self.out_proj.weight.device\n        conv_dtype = self.conv1d.weight.dtype if dtype is None else dtype\n        conv_state = torch.zeros(\n            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype\n        )\n        ssm_dtype = self.dt_proj.weight.dtype if dtype is None else dtype\n        # ssm_dtype = torch.float32\n        ssm_state = torch.zeros(\n            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype\n        )\n        return conv_state, ssm_state\n\n    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):\n        assert self.layer_idx is not None\n        if self.layer_idx not in inference_params.key_value_memory_dict:\n            batch_shape = (batch_size,)\n            conv_state = torch.zeros(\n                batch_size,\n                self.d_model * self.expand,\n                self.d_conv,\n                device=self.conv1d.weight.device,\n                dtype=self.conv1d.weight.dtype,\n            )\n            ssm_state = torch.zeros(\n                batch_size,\n                self.d_model * self.expand,\n                self.d_state,\n                device=self.dt_proj.weight.device,\n                dtype=self.dt_proj.weight.dtype,\n                # dtype=torch.float32,\n            )\n            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)\n        else:\n            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]\n            # TODO: What if batch size changes between generation, and we reuse the same states?\n            if initialize_states:\n                conv_state.zero_()\n                ssm_state.zero_()\n        return conv_state, ssm_state","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:51.834057Z","iopub.execute_input":"2024-12-03T13:19:51.834549Z","iopub.status.idle":"2024-12-03T13:19:52.216537Z","shell.execute_reply.started":"2024-12-03T13:19:51.834488Z","shell.execute_reply":"2024-12-03T13:19:52.215647Z"},"papermill":{"duration":0.066382,"end_time":"2024-12-02T19:10:39.126908","exception":false,"start_time":"2024-12-02T19:10:39.060526","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copyright (c) MONAI Consortium\n\nfrom __future__ import annotations\nimport torch.nn as nn\nimport torch \nfrom functools import partial\n\nfrom monai.networks.blocks.dynunet_block import UnetOutBlock\nfrom monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrUpBlock\nfrom mamba_ssm import Mamba\nimport torch.nn.functional as F \n\nclass LayerNorm(nn.Module):\n    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n    with shape (batch_size, channels, height, width).\n    \"\"\"\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError\n        self.normalized_shape = (normalized_shape, )\n\n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n\n            return x\n\nclass MambaLayer(nn.Module):\n    def __init__(self, dim, d_state = 16, d_conv = 4, expand = 2, num_slices=None):\n        super().__init__()\n        self.dim = dim\n        self.norm = nn.LayerNorm(dim)\n        self.mamba = XMamba(\n                d_model=dim,\n                d_state=d_state, \n                d_conv=d_conv,\n                expand=expand,\n                nslices=num_slices,\n        )\n    \n    def forward(self, x):\n        B, C = x.shape[:2]\n        x_skip = x\n        assert C == self.dim\n        n_tokens = x.shape[2:].numel()\n        img_dims = x.shape[2:]\n        x_flat = x.reshape(B, C, n_tokens).transpose(-1, -2)\n        x_norm = self.norm(x_flat)\n        x_mamba = self.mamba(x_norm)\n        out = x_mamba.transpose(-1, -2).reshape(B, C, *img_dims)\n        out = out + x_skip\n        act = nn.GELU()\n        \n        return act(out)\n    \nclass MlpChannel(nn.Module):\n    def __init__(self,hidden_size, mlp_dim, ):\n        super().__init__()\n        self.fc1 = nn.Conv3d(hidden_size, mlp_dim, 1)\n        self.act = nn.GELU()\n        self.fc2 = nn.Conv3d(mlp_dim, hidden_size, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.fc2(x)\n        return x\n\nclass GSC(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        \n        self.DW_Conv = nn.Sequential(\n            nn.Conv3d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm3d(in_channels),\n            nn.ReLU()\n        )\n\n        self.PW_Conv = nn.Sequential(\n            nn.Conv3d(in_channels, in_channels, kernel_size=1, stride=1, padding=0),\n            nn.InstanceNorm3d(in_channels),\n            nn.ReLU()\n        )\n    \n    def forward(self, x):\n        \n        x = self.DW_Conv(x)\n        residual = x\n        out = self.PW_Conv(x)\n        \n        return out + residual\n\nclass MambaEncoder(nn.Module):\n    def __init__(self, in_chans=1, depths=[2, 2, 2, 2], dims=[48, 96, 192, 384],\n                 drop_path_rate=0., layer_scale_init_value=1e-6, out_indices=[0, 1, 2, 3]):\n        super().__init__()\n\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n        stem = nn.Sequential(\n              nn.Conv3d(in_chans, dims[0], kernel_size=7, stride=2, padding=3),\n        )\n        self.downsample_layers.append(stem)\n        for i in range(3):\n            downsample_layer = nn.Sequential(\n                nn.InstanceNorm3d(dims[i]),\n                nn.Conv3d(dims[i], dims[i+1], kernel_size=2, stride=2),\n            )\n            self.downsample_layers.append(downsample_layer)\n\n        self.stages = nn.ModuleList()\n        self.gscs = nn.ModuleList()\n        num_slices_list = [64, 32, 16, 8]\n        cur = 0\n        for i in range(4):\n            gsc = GSC(dims[i])\n\n            stage = nn.Sequential(\n                *[MambaLayer(dim=dims[i], num_slices=num_slices_list[i]) for j in range(depths[i])]\n            )\n\n            self.stages.append(stage)\n            self.gscs.append(gsc)\n            cur += depths[i]\n\n        self.out_indices = out_indices\n\n        self.mlps = nn.ModuleList()\n        for i_layer in range(4):\n            layer = nn.InstanceNorm3d(dims[i_layer])\n            layer_name = f'norm{i_layer}'\n            self.add_module(layer_name, layer)\n            self.mlps.append(MlpChannel(dims[i_layer], 2 * dims[i_layer]))\n\n    def forward_features(self, x):\n        outs = []\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.gscs[i](x)\n            x = self.stages[i](x)\n\n            if i in self.out_indices:\n                norm_layer = getattr(self, f'norm{i}')\n                x_out = norm_layer(x)\n                x_out = self.mlps[i](x_out)\n                outs.append(x_out)\n\n        return tuple(outs)\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        return x\n\nclass SegMamba(nn.Module):\n    def __init__(\n        self,\n        in_chans=1,\n        out_chans=13,\n        depths=[2, 2, 2, 2],\n        feat_size=[48, 96, 192, 384],\n        drop_path_rate=0,\n        layer_scale_init_value=1e-6,\n        hidden_size: int = 768,\n        norm_name = \"instance\",\n        conv_block: bool = True,\n        res_block: bool = True,\n        spatial_dims=3,\n    ) -> None:\n        super().__init__()\n\n        self.hidden_size = hidden_size\n        self.in_chans = in_chans\n        self.out_chans = out_chans\n        self.depths = depths\n        self.drop_path_rate = drop_path_rate\n        self.feat_size = feat_size\n        self.layer_scale_init_value = layer_scale_init_value\n\n        self.spatial_dims = spatial_dims\n        self.vit = MambaEncoder(in_chans, \n                                depths=depths,\n                                dims=feat_size,\n                                drop_path_rate=drop_path_rate,\n                                layer_scale_init_value=layer_scale_init_value,\n                              )\n        self.encoder1 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.in_chans,\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder2 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[0],\n            out_channels=self.feat_size[1],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder3 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[1],\n            out_channels=self.feat_size[2],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.encoder4 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[2],\n            out_channels=self.feat_size[3],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n\n        self.encoder5 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[3],\n            out_channels=self.hidden_size,\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n\n        self.decoder5 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.hidden_size,\n            out_channels=self.feat_size[3],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder4 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[3],\n            out_channels=self.feat_size[2],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder3 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[2],\n            out_channels=self.feat_size[1],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder2 = UnetrUpBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[1],\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            upsample_kernel_size=2,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.decoder1 = UnetrBasicBlock(\n            spatial_dims=spatial_dims,\n            in_channels=self.feat_size[0],\n            out_channels=self.feat_size[0],\n            kernel_size=3,\n            stride=1,\n            norm_name=norm_name,\n            res_block=res_block,\n        )\n        self.out = UnetOutBlock(spatial_dims=spatial_dims, in_channels=48, out_channels=self.out_chans)\n\n    def forward(self, x_in):\n        outs = self.vit(x_in)\n        enc1 = self.encoder1(x_in)\n        x2 = outs[0]\n        enc2 = self.encoder2(x2)\n        x3 = outs[1]\n        enc3 = self.encoder3(x3)\n        x4 = outs[2]\n        enc4 = self.encoder4(x4)\n        enc_hidden = self.encoder5(outs[3])\n        dec3 = self.decoder5(enc_hidden, enc4)\n        dec2 = self.decoder4(dec3, enc3)\n        dec1 = self.decoder3(dec2, enc2)\n        dec0 = self.decoder2(dec1, enc1)\n        out = self.decoder1(dec0)\n                \n        return self.out(out)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:52.217956Z","iopub.execute_input":"2024-12-03T13:19:52.218344Z","iopub.status.idle":"2024-12-03T13:19:52.248694Z","shell.execute_reply.started":"2024-12-03T13:19:52.218305Z","shell.execute_reply":"2024-12-03T13:19:52.247852Z"},"papermill":{"duration":0.045705,"end_time":"2024-12-02T19:10:39.212384","exception":false,"start_time":"2024-12-02T19:10:39.166679","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:52.249760Z","iopub.execute_input":"2024-12-03T13:19:52.250004Z","iopub.status.idle":"2024-12-03T13:19:52.262020Z","shell.execute_reply.started":"2024-12-03T13:19:52.249981Z","shell.execute_reply":"2024-12-03T13:19:52.261323Z"},"papermill":{"duration":0.019475,"end_time":"2024-12-02T19:10:39.245397","exception":false,"start_time":"2024-12-02T19:10:39.225922","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Optimizer and loss function","metadata":{"papermill":{"duration":0.013057,"end_time":"2024-12-02T19:10:39.272274","exception":false,"start_time":"2024-12-02T19:10:39.259217","status":"completed"},"tags":[]}},{"cell_type":"code","source":"max_epochs = 120\nval_interval = 1\nVAL_AMP = True\nroi = (128, 128, 128)\n\ndevice = torch.device(\"cuda\")\nmodel = SegMamba(in_chans=4,\n                 out_chans=4,\n                 depths=[2,2,2,2],\n                 feat_size=[48, 96, 192, 384]).to(device)\n\n\nloss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\noptimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=120)\n\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\")\ndice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n\npost_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n\n# define inference method\ndef inference(input):\n    def _compute(input):\n        return sliding_window_inference(\n            inputs=input,\n            roi_size=(128, 128, 128),\n            sw_batch_size=1,\n            predictor=model,\n            overlap=0.5,\n        )\n\n    if VAL_AMP:\n        with torch.amp.autocast(device_type='cuda'):\n            return _compute(input)\n    else:\n        return _compute(input)\n\n\n# use amp to accelerate training\nscaler = torch.amp.GradScaler('cuda')\n# enable cuDNN benchmark\ntorch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:52.263003Z","iopub.execute_input":"2024-12-03T13:19:52.263335Z","iopub.status.idle":"2024-12-03T13:19:53.279737Z","shell.execute_reply.started":"2024-12-03T13:19:52.263300Z","shell.execute_reply":"2024-12-03T13:19:53.278816Z"},"papermill":{"duration":0.998368,"end_time":"2024-12-02T19:10:40.283874","exception":false,"start_time":"2024-12-02T19:10:39.285506","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Finetunning","metadata":{"papermill":{"duration":0.013306,"end_time":"2024-12-02T19:10:40.311111","exception":false,"start_time":"2024-12-02T19:10:40.297805","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def load_checkpoint(filename, model, optimizer=None, lr_scheduler=None):\n    checkpoint = torch.load(filename)\n    \n    model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n    \n    print(f\"Checkpoint loaded: Epoch {checkpoint['epoch']}, Best Accuracy: {checkpoint['best_acc']}\")\n\n    if optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n    \n    if lr_scheduler is not None:\n        lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler_state_dict\"])\n    \n    return checkpoint[\"epoch\"], checkpoint[\"best_acc\"]","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:53.280937Z","iopub.execute_input":"2024-12-03T13:19:53.281285Z","iopub.status.idle":"2024-12-03T13:19:53.286865Z","shell.execute_reply.started":"2024-12-03T13:19:53.281249Z","shell.execute_reply":"2024-12-03T13:19:53.285968Z"},"papermill":{"duration":0.020829,"end_time":"2024-12-02T19:10:40.345431","exception":false,"start_time":"2024-12-02T19:10:40.324602","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_file = '/kaggle/input/pretrain/model.pt'\n\n# start_epoch, best_acc = load_checkpoint(\n#     checkpoint_file, \n#     model, \n#     optimizer=optimizer, \n#     lr_scheduler=lr_scheduler\n# )","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:53.287889Z","iopub.execute_input":"2024-12-03T13:19:53.288181Z","iopub.status.idle":"2024-12-03T13:19:53.296033Z","shell.execute_reply.started":"2024-12-03T13:19:53.288157Z","shell.execute_reply":"2024-12-03T13:19:53.295360Z"},"papermill":{"duration":0.018995,"end_time":"2024-12-02T19:10:40.377696","exception":false,"start_time":"2024-12-02T19:10:40.358701","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Execute training","metadata":{"papermill":{"duration":0.013258,"end_time":"2024-12-02T19:10:40.404286","exception":false,"start_time":"2024-12-02T19:10:40.391028","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def save_checkpoint(optimizer, lr_scheduler, model, epoch, filename=\"model.pt\", best_acc=0, dir_add=\"./\"):\n    state_dict = model.state_dict()\n    optimizer_state_dict = optimizer.state_dict()\n    lr_scheduler_state_dict = lr_scheduler.state_dict()\n    \n    save_dict = {\n        \"epoch\": epoch,\n        \"best_acc\": best_acc,\n        \"state_dict\": state_dict,\n        \"optimizer_state_dict\": optimizer_state_dict,\n        \"lr_scheduler_state_dict\": lr_scheduler_state_dict,\n    }\n    \n    filename = os.path.join(dir_add, filename)\n    torch.save(save_dict, filename)\n    print(f\"Checkpoint saved at {filename}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:53.296933Z","iopub.execute_input":"2024-12-03T13:19:53.297189Z","iopub.status.idle":"2024-12-03T13:19:53.309856Z","shell.execute_reply.started":"2024-12-03T13:19:53.297164Z","shell.execute_reply":"2024-12-03T13:19:53.309143Z"},"papermill":{"duration":0.021351,"end_time":"2024-12-02T19:10:40.439203","exception":false,"start_time":"2024-12-02T19:10:40.417852","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:53.310851Z","iopub.execute_input":"2024-12-03T13:19:53.311182Z","iopub.status.idle":"2024-12-03T13:19:53.321941Z","shell.execute_reply.started":"2024-12-03T13:19:53.311143Z","shell.execute_reply":"2024-12-03T13:19:53.321232Z"},"papermill":{"duration":0.019141,"end_time":"2024-12-02T19:10:40.471531","exception":false,"start_time":"2024-12-02T19:10:40.452390","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_metric = -1\nbest_metric_epoch = -1\nbest_metrics_epochs_and_time = [[], [], []]\nepoch_loss_values = []\nmetric_values = []\nmetric_values_tc = []\nmetric_values_wt = [] \nmetric_values_et = []\nmetric_values_rc = []\n\ntotal_start = time.time()\nfor epoch in tqdm(range(max_epochs), desc=\"Training Epochs\"):\n    epoch_start = time.time()\n    print(\"-\" * 10)\n    print(f\"epoch {epoch + 1}/{max_epochs}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step_start = time.time()\n        step += 1\n        inputs, labels = (\n            batch_data[\"image\"].to(device),\n            batch_data[\"label\"].to(device),\n        )\n        optimizer.zero_grad()\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(inputs)\n            loss = loss_function(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n\n    lr_scheduler.step()\n    epoch_loss /= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            for val_data in val_loader:\n                val_inputs, val_labels = (\n                    val_data[\"image\"].to(device),\n                    val_data[\"label\"].to(device),\n                )\n                val_outputs = inference(val_inputs)\n                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n                \n                # Đo lường và tính toán các metrics cho từng lớp\n                dice_metric(y_pred=val_outputs, y=val_labels)\n                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n\n\n            # Tính tổng Dice score cho tất cả lớp (mean dice)\n            metric = dice_metric.aggregate().item()\n            metric_values.append(metric)\n\n            # Các giá trị Dice cho từng lớp cụ thể\n            metric_batch = dice_metric_batch.aggregate()\n            metric_tc = metric_batch[0].item() \n            metric_values_tc.append(metric_tc)\n            metric_wt = metric_batch[1].item()\n            metric_values_wt.append(metric_wt)\n            metric_et = metric_batch[2].item()\n            metric_values_et.append(metric_et)\n            metric_rc = metric_batch[3].item()\n            metric_values_rc.append(metric_rc)\n\n            dice_metric.reset()\n            dice_metric_batch.reset()\n\n            if metric > best_metric:\n                best_metric = metric\n                best_metric_epoch = epoch + 1\n                best_metrics_epochs_and_time[0].append(best_metric)\n                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n                save_checkpoint(\n                    optimizer,\n                    lr_scheduler,\n                    model,\n                    epoch,\n                    best_acc=best_metric,\n                )\n    \n                print(\"saved new best metric model\")\n\n            print(\n                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f} \\n\"\n                f\"tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f} rc: {metric_rc:.4f} \\n\"\n                f\"Best mean dice: {best_metric:.4f} \\n\"\n                f\"at epoch: {best_metric_epoch}\"\n            )\n    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\ntotal_time = time.time() - total_start","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:19:53.322996Z","iopub.execute_input":"2024-12-03T13:19:53.323233Z","iopub.status.idle":"2024-12-03T13:25:35.937063Z","shell.execute_reply.started":"2024-12-03T13:19:53.323211Z","shell.execute_reply":"2024-12-03T13:25:35.935535Z"},"papermill":{"duration":40978.204825,"end_time":"2024-12-03T06:33:38.689585","exception":false,"start_time":"2024-12-02T19:10:40.484760","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_time = time.time() - total_start","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.938290Z","iopub.status.idle":"2024-12-03T13:25:35.939365Z","shell.execute_reply.started":"2024-12-03T13:25:35.939114Z","shell.execute_reply":"2024-12-03T13:25:35.939143Z"},"papermill":{"duration":0.038253,"end_time":"2024-12-03T06:33:38.756406","exception":false,"start_time":"2024-12-03T06:33:38.718153","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.940482Z","iopub.status.idle":"2024-12-03T13:25:35.940969Z","shell.execute_reply.started":"2024-12-03T13:25:35.940729Z","shell.execute_reply":"2024-12-03T13:25:35.940754Z"},"papermill":{"duration":0.03411,"end_time":"2024-12-03T06:33:38.819132","exception":false,"start_time":"2024-12-03T06:33:38.785022","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot the loss and Dice metric","metadata":{"papermill":{"duration":0.032147,"end_time":"2024-12-03T06:33:38.879913","exception":false,"start_time":"2024-12-03T06:33:38.847766","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Đoạn vẽ đồ thị cho loss và Dice mean\nplt.figure(\"train\", (12, 6))\n\n# Vẽ Epoch Average Loss\nplt.subplot(1, 2, 1)\nplt.title(\"Epoch Average Loss\")\nx = [i + 1 for i in range(len(epoch_loss_values))]\ny = epoch_loss_values\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.plot(x, y, color=\"red\")\n\n# Vẽ Val Mean Dice\nplt.subplot(1, 2, 2)\nplt.title(\"Val Mean Dice\")\nx = [val_interval * (i + 1) for i in range(len(metric_values))]\ny = metric_values\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.plot(x, y, color=\"green\")\n\nplt.show()\n\n# Đoạn vẽ đồ thị cho các lớp (TC, WT, ET, RC)\nplt.figure(\"train\", (18, 6))\n\n# Val Mean Dice TC (Tumor Core)\nplt.subplot(1, 4, 1)\nplt.title(\"Val Mean Dice TC\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\ny = metric_values_tc\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.plot(x, y, color=\"brown\")\n\n# Val Mean Dice WT\nplt.subplot(1, 4, 2)\nplt.title(\"Val Mean Dice WT\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\ny = metric_values_wt\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.plot(x, y, color=\"purple\")\n\n# Val Mean Dice ET\nplt.subplot(1, 4, 3)\nplt.title(\"Val Mean Dice ET\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_et))]\ny = metric_values_et\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.plot(x, y, color=\"orange\")\n\nplt.subplot(1, 4, 4)\nplt.title(\"Val Mean Dice RC\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_rc))]\ny = metric_values_rc\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.plot(x, y, color=\"blue\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.942201Z","iopub.status.idle":"2024-12-03T13:25:35.942660Z","shell.execute_reply.started":"2024-12-03T13:25:35.942404Z","shell.execute_reply":"2024-12-03T13:25:35.942426Z"},"papermill":{"duration":1.165342,"end_time":"2024-12-03T06:33:40.074705","exception":false,"start_time":"2024-12-03T06:33:38.909363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf_loss = pd.DataFrame({\n    \"Epoch\": range(1, len(epoch_loss_values) + 1),\n    \"Loss\": epoch_loss_values\n})\ndf_loss.to_csv(\"epoch_loss_values.csv\", index=False)\n\ndf_metric = pd.DataFrame({\n    \"Epoch\": [val_interval * (i + 1) for i in range(len(metric_values))],\n    \"Dice Score\": metric_values\n})\ndf_metric.to_csv(\"metric_values.csv\", index=False)\n\nclasses = {\n    \"metric_values_tc\": metric_values_tc,\n    \"metric_values_wt\": metric_values_wt,\n    \"metric_values_et\": metric_values_et,\n    \"metric_values_rc\": metric_values_rc\n}\n\nfor class_name, values in classes.items():\n    df = pd.DataFrame({\n        \"Epoch\": [val_interval * (i + 1) for i in range(len(values))],\n        \"Dice Score\": values\n    })\n    df.to_csv(f\"{class_name}.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.943813Z","iopub.status.idle":"2024-12-03T13:25:35.944241Z","shell.execute_reply.started":"2024-12-03T13:25:35.944019Z","shell.execute_reply":"2024-12-03T13:25:35.944042Z"},"papermill":{"duration":0.075677,"end_time":"2024-12-03T06:33:40.180764","exception":false,"start_time":"2024-12-03T06:33:40.105087","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create test set dataloader","metadata":{"papermill":{"duration":0.030428,"end_time":"2024-12-03T06:33:40.241216","exception":false,"start_time":"2024-12-03T06:33:40.210788","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Các modal cần xử lý\nmodalities = [\"t1n\", \"t1c\", \"t2f\", \"t2w\"]\n\n# Tạo danh sách test_files tự động\ntest_files = [\n    {\n        \"image\": [\n            f\"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-{modality}.nii\"\n            for modality in modalities\n        ],\n        \"label\": \"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-seg.nii\",\n    }\n]\n\ntest_transform = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n    ]\n)\n\ntest_ds = Dataset(data=test_files, transform=test_transform)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=1,\n    shuffle=False,\n    num_workers=8,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.946321Z","iopub.status.idle":"2024-12-03T13:25:35.946776Z","shell.execute_reply.started":"2024-12-03T13:25:35.946549Z","shell.execute_reply":"2024-12-03T13:25:35.946571Z"},"papermill":{"duration":0.04174,"end_time":"2024-12-03T06:33:40.313908","exception":false,"start_time":"2024-12-03T06:33:40.272168","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the best saved checkpoint and perform inference \n\n\n\nWe select a single case from the validation set and perform inference to compare the model segmentation output with the corresponding label. ","metadata":{"papermill":{"duration":0.030318,"end_time":"2024-12-03T06:33:40.375590","exception":false,"start_time":"2024-12-03T06:33:40.345272","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.load_state_dict(torch.load(os.path.join(\"model.pt\"))[\"state_dict\"])\nmodel.to(device)\nmodel.eval()\n\nmodel_inferer_test = partial(\n    sliding_window_inference,\n    roi_size=[roi[0], roi[1], roi[2]],\n    sw_batch_size=1,\n    predictor=model,\n    overlap=0.6,\n)\n\n\nwith torch.no_grad():\n    for batch_data in test_loader:\n        image = batch_data[\"image\"].to(device)\n        prob = torch.sigmoid(model_inferer_test(image))\n        seg = prob[0].detach().cpu().numpy()\n        seg = (seg > 0.5).astype(np.int8)\n        seg_out = np.zeros((seg.shape[1], seg.shape[2], seg.shape[3]))\n        seg_out[seg[1] == 1] = 2\n        seg_out[seg[0] == 1] = 1\n        seg_out[seg[2] == 1] = 3\n        seg_out[seg[3] == 1] = 4","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.948122Z","iopub.status.idle":"2024-12-03T13:25:35.948569Z","shell.execute_reply.started":"2024-12-03T13:25:35.948325Z","shell.execute_reply":"2024-12-03T13:25:35.948347Z"},"papermill":{"duration":112.713656,"end_time":"2024-12-03T06:35:33.119281","exception":false,"start_time":"2024-12-03T06:33:40.405625","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize segmentation output and compare with label","metadata":{"papermill":{"duration":0.037265,"end_time":"2024-12-03T06:35:33.196823","exception":false,"start_time":"2024-12-03T06:35:33.159558","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with torch.no_grad():\n    # select one image to evaluate and visualize the model output\n    val_input = val_ds[3][\"image\"].unsqueeze(0).to(device)\n    roi_size = (128, 128, 128)\n    sw_batch_size = 4\n    val_output = inference(val_input)\n    val_output = post_trans(val_output[0])\n    plt.figure(\"image\", (24, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"image channel {i}\")\n        plt.imshow(val_ds[3][\"image\"][i, :, :, 64].detach().cpu(), cmap=\"gray\")\n    plt.show()\n    # visualize the 4 channels label corresponding to this image\n    plt.figure(\"label\", (18, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"label channel {i}\")\n        plt.imshow(val_ds[3][\"label\"][i, :, :, 64].detach().cpu())\n    plt.show()\n    # visualize the 4 channels model output corresponding to this image\n    plt.figure(\"output\", (18, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"output channel {i}\")\n        plt.imshow(val_output[i, :, :, 64].detach().cpu())\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.950849Z","iopub.status.idle":"2024-12-03T13:25:35.951307Z","shell.execute_reply.started":"2024-12-03T13:25:35.951074Z","shell.execute_reply":"2024-12-03T13:25:35.951098Z"},"papermill":{"duration":17.243915,"end_time":"2024-12-03T06:35:50.475605","exception":false,"start_time":"2024-12-03T06:35:33.231690","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"slice_num = 90\n\nimg_add = os.path.join(\"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-t1c.nii\")\n\nlabel_add = os.path.join(\"/kaggle/input/BraTS2024_small_dataset/BraTS-GLI-02063-105/BraTS-GLI-02063-105-seg.nii\")\n\nimg = nib.load(img_add).get_fdata()\n\nlabel = nib.load(label_add).get_fdata()\n\nplt.figure(\"image\", (18, 6))\n\nplt.subplot(1, 3, 1)\n\nplt.title(\"image\")\n\nplt.imshow(img[:, :, slice_num], cmap=\"gray\")\n\nplt.subplot(1, 3, 2)\n\nplt.title(\"label\")\n\nplt.imshow(label[:, :, slice_num])\n\nplt.subplot(1, 3, 3)\n\nplt.title(\"segmentation\")\n\nplt.imshow(seg_out[:, :, slice_num])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.952363Z","iopub.status.idle":"2024-12-03T13:25:35.952821Z","shell.execute_reply.started":"2024-12-03T13:25:35.952593Z","shell.execute_reply":"2024-12-03T13:25:35.952615Z"},"papermill":{"duration":0.726116,"end_time":"2024-12-03T06:35:51.235416","exception":false,"start_time":"2024-12-03T06:35:50.509300","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save model.pt","metadata":{"papermill":{"duration":0.035174,"end_time":"2024-12-03T06:35:51.306456","exception":false,"start_time":"2024-12-03T06:35:51.271282","status":"completed"},"tags":[]}},{"cell_type":"code","source":"torch.save(torch.load(os.path.join(\"model.pt\")), \"/kaggle/working/model.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.953711Z","iopub.status.idle":"2024-12-03T13:25:35.954125Z","shell.execute_reply.started":"2024-12-03T13:25:35.953909Z","shell.execute_reply":"2024-12-03T13:25:35.953932Z"},"papermill":{"duration":3.123076,"end_time":"2024-12-03T06:35:54.464094","exception":false,"start_time":"2024-12-03T06:35:51.341018","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cleanup data directory\n\n\n\nRemove directory if a temporary was used.","metadata":{"papermill":{"duration":0.037573,"end_time":"2024-12-03T06:35:54.542169","exception":false,"start_time":"2024-12-03T06:35:54.504596","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if directory is None:\n    shutil.rmtree(root_dir)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T13:25:35.955686Z","iopub.status.idle":"2024-12-03T13:25:35.955973Z","shell.execute_reply.started":"2024-12-03T13:25:35.955841Z","shell.execute_reply":"2024-12-03T13:25:35.955855Z"},"papermill":{"duration":0.048497,"end_time":"2024-12-03T06:35:54.629071","exception":false,"start_time":"2024-12-03T06:35:54.580574","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}